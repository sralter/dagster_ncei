{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dagster and Weather Data\n",
    "Exploring these tools through a practical example of retrieving climate data from datasets like the NCEI or weather.gov's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyncei import NCEIBot\n",
    "import re\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import StringIO\n",
    "import polars as pl\n",
    "import dask.dataframe as dd\n",
    "from datetime import datetime\n",
    "import leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to install uv are below. Note that each line is run sequentially. First, navigate to your project's directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```zsh\n",
    "uv venv --python=python3.11\n",
    "source .venv/bin/activate  # (On macOS/Linux)\n",
    "# .venv\\Scripts\\activate  # (On Windows)\n",
    "uv pip install geospatial\n",
    "uv pip install dagster\n",
    "uv pip install pyncei\n",
    "# Optional commands\n",
    "pip list\n",
    "pip freeze > requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## api.weather.gov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define header token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weather_token.txt', 'r') as file:\n",
    "    email = file.read().strip()\n",
    "\n",
    "headers = {\"User-Agent\": f\"MyWeatherApp/1.0 ({email})\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define location for forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hayden Planetarium, American Museum of Natural History\n",
    "lat, lon = 40.78150, -73.97321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get seven-day weather forecast for **_RIGHT NOW_**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date is: 2025-01-10 19:41:04\n",
      "*****\n",
      "        Tonight (2025-01-10): Cloudy then Snow Showers Likely, 30°F\n",
      "       Saturday (2025-01-11): Snow Showers Likely then Mostly Cloudy, 36°F\n",
      " Saturday Night (2025-01-11): Mostly Clear, 29°F\n",
      "         Sunday (2025-01-12): Sunny, 41°F\n",
      "   Sunday Night (2025-01-12): Partly Cloudy, 29°F\n",
      "         Monday (2025-01-13): Mostly Sunny, 40°F\n",
      "   Monday Night (2025-01-13): Partly Cloudy, 28°F\n",
      "        Tuesday (2025-01-14): Mostly Sunny, 32°F\n",
      "  Tuesday Night (2025-01-14): Partly Cloudy, 21°F\n",
      "      Wednesday (2025-01-15): Mostly Sunny, 31°F\n",
      "Wednesday Night (2025-01-15): Mostly Clear, 21°F\n",
      "       Thursday (2025-01-16): Mostly Sunny, 32°F\n",
      " Thursday Night (2025-01-16): Partly Cloudy, 24°F\n",
      "         Friday (2025-01-17): Mostly Sunny, 36°F\n"
     ]
    }
   ],
   "source": [
    "def fetch_data(url, headers):\n",
    "    \"\"\"Fetch data from the given URL with specified headers.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error {response.status_code}: {response.text}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Network error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 1: Get metadata for the location\n",
    "points_url = f'https://api.weather.gov/points/{lat},{lon}'\n",
    "points_data = fetch_data(points_url, headers)\n",
    "\n",
    "if points_data:\n",
    "    now = datetime.now()\n",
    "    print(f\"The date is: {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print('*' * 5)\n",
    "    # Step 2: Get the forecast URL\n",
    "    forecast_url = points_data.get('properties', {}).get('forecast')\n",
    "    if forecast_url:\n",
    "        # Step 3: Get the forecast data\n",
    "        forecast_data = fetch_data(forecast_url, headers)\n",
    "        if forecast_data:\n",
    "            # Extract the time of the request and forecast update\n",
    "            update_time = forecast_data.get('properties', {}).get('updated')\n",
    "            if update_time:\n",
    "                request_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(f\"Request Time: {request_time}\")\n",
    "                print(f\"Forecast Updated: {update_time}\")\n",
    "\n",
    "            # Extract and display forecast periods\n",
    "            periods = forecast_data.get('properties', {}).get('periods', [])\n",
    "            for period in periods:\n",
    "                start_time = period.get('startTime', '').split(\"T\")[0]  # Extract date\n",
    "                print(f\"{period['name']:>15} ({start_time}): {period['shortForecast']}, {period['temperature']}°{period['temperatureUnit']}\")\n",
    "        else:\n",
    "            print(\"Unable to fetch forecast data.\")\n",
    "    else:\n",
    "        print(\"Forecast URL not found in the response.\")\n",
    "else:\n",
    "    print(\"Unable to fetch metadata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22e3e45240d433f9db411a0a93253cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40.7815, -73.9732], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'z…"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon = points_data['geometry']['coordinates'][0]\n",
    "lat = points_data['geometry']['coordinates'][1]\n",
    "\n",
    "m = leafmap.Map(center=[lat,lon], zoom=16)\n",
    "m.add_marker(location=[lat,lon])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['@context', 'id', 'type', 'geometry', 'properties'])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@id': 'https://api.weather.gov/points/40.7815,-73.9732',\n",
       " '@type': 'wx:Point',\n",
       " 'cwa': 'OKX',\n",
       " 'forecastOffice': 'https://api.weather.gov/offices/OKX',\n",
       " 'gridId': 'OKX',\n",
       " 'gridX': 34,\n",
       " 'gridY': 38,\n",
       " 'forecast': 'https://api.weather.gov/gridpoints/OKX/34,38/forecast',\n",
       " 'forecastHourly': 'https://api.weather.gov/gridpoints/OKX/34,38/forecast/hourly',\n",
       " 'forecastGridData': 'https://api.weather.gov/gridpoints/OKX/34,38',\n",
       " 'observationStations': 'https://api.weather.gov/gridpoints/OKX/34,38/stations',\n",
       " 'relativeLocation': {'type': 'Feature',\n",
       "  'geometry': {'type': 'Point', 'coordinates': [-74.004572, 40.792784]},\n",
       "  'properties': {'city': 'Guttenberg',\n",
       "   'state': 'NJ',\n",
       "   'distance': {'unitCode': 'wmoUnit:m', 'value': 2924.1050495133},\n",
       "   'bearing': {'unitCode': 'wmoUnit:degree_(angle)', 'value': 115}}},\n",
       " 'forecastZone': 'https://api.weather.gov/zones/forecast/NYZ072',\n",
       " 'county': 'https://api.weather.gov/zones/county/NYC061',\n",
       " 'fireWeatherZone': 'https://api.weather.gov/zones/fire/NYZ212',\n",
       " 'timeZone': 'America/New_York',\n",
       " 'radarStation': 'KOKX'}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_data['properties']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make figure showing seven-day forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make dagster portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCEI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read NCEI token from text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ncei_token.txt', 'r') as file:\n",
    "    token = file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass token to the `NCEIBot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  ...           retrieved\n",
      "0        GHCND  ... 2025-01-09 22:17:23\n",
      "1         GSOM  ... 2025-01-09 22:17:23\n",
      "2         GSOY  ... 2025-01-09 22:17:23\n",
      "3      NEXRAD2  ... 2025-01-09 22:17:23\n",
      "4      NEXRAD3  ... 2025-01-09 22:17:23\n",
      "5   NORMAL_ANN  ... 2025-01-09 22:17:23\n",
      "6   NORMAL_DLY  ... 2025-01-09 22:17:23\n",
      "7   NORMAL_HLY  ... 2025-01-09 22:17:23\n",
      "8   NORMAL_MLY  ... 2025-01-09 22:17:23\n",
      "9    PRECIP_15  ... 2025-01-09 22:17:23\n",
      "10  PRECIP_HLY  ... 2025-01-09 22:17:23\n",
      "\n",
      "[11 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "ncei = NCEIBot(token, cache_name='ncei_cache')\n",
    "\n",
    "# find datasets related to precipitation\n",
    "datasets = ncei.get_datasets()\n",
    "print(datasets.to_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup all the stations in the [Global Historical Climatology Network daily (GHCNd)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (128_025, 8)\n",
      "┌─────────────┬──────────┬───────────┬───────────┬────────────────────┬──────┬──────┬──────────────┐\n",
      "│ station_id  ┆ latitude ┆ longitude ┆ elevation ┆ description        ┆ flag ┆ gsn  ┆ station_name │\n",
      "│ ---         ┆ ---      ┆ ---       ┆ ---       ┆ ---                ┆ ---  ┆ ---  ┆ ---          │\n",
      "│ str         ┆ f64      ┆ f64       ┆ f64       ┆ str                ┆ str  ┆ str  ┆ f64          │\n",
      "╞═════════════╪══════════╪═══════════╪═══════════╪════════════════════╪══════╪══════╪══════════════╡\n",
      "│ ACW00011604 ┆ 17.1167  ┆ -61.7833  ┆ 10.1      ┆ ST JOHNS COOLIDGE  ┆ null ┆ null ┆ null         │\n",
      "│             ┆          ┆           ┆           ┆ FLD                ┆      ┆      ┆              │\n",
      "│ ACW00011647 ┆ 17.1333  ┆ -61.7833  ┆ 19.2      ┆ ST JOHNS           ┆ null ┆ null ┆ null         │\n",
      "│ AE000041196 ┆ 25.333   ┆ 55.517    ┆ 34.0      ┆ SHARJAH INTER.     ┆ null ┆ GSN  ┆ 41196.0      │\n",
      "│             ┆          ┆           ┆           ┆ AIRP               ┆      ┆      ┆              │\n",
      "│ AEM00041194 ┆ 25.255   ┆ 55.364    ┆ 10.4      ┆ DUBAI INTL         ┆ null ┆ null ┆ 41194.0      │\n",
      "│ AEM00041217 ┆ 24.433   ┆ 54.651    ┆ 26.8      ┆ ABU DHABI INTL     ┆ null ┆ null ┆ 41217.0      │\n",
      "│ …           ┆ …        ┆ …         ┆ …         ┆ …                  ┆ …    ┆ …    ┆ …            │\n",
      "│ ZI000067969 ┆ 21.05    ┆ 29.367    ┆ 861.0     ┆ WEST NICHOLSON     ┆ null ┆ null ┆ 67969.0      │\n",
      "│ ZI000067975 ┆ 20.067   ┆ 30.867    ┆ 1095.0    ┆ MASVINGO           ┆ null ┆ null ┆ 67975.0      │\n",
      "│ ZI000067977 ┆ 21.017   ┆ 31.583    ┆ 430.0     ┆ BUFFALO RANGE      ┆ null ┆ null ┆ 67977.0      │\n",
      "│ ZI000067983 ┆ 20.2     ┆ 32.616    ┆ 1132.0    ┆ CHIPINGE           ┆ null ┆ GSN  ┆ 67983.0      │\n",
      "│ ZI000067991 ┆ 22.217   ┆ 30.0      ┆ 457.0     ┆ BEITBRIDGE         ┆ null ┆ null ┆ 67991.0      │\n",
      "└─────────────┴──────────┴───────────┴───────────┴────────────────────┴──────┴──────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# fetch file from URL\n",
    "url_dict = {\n",
    "    'stations': 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt',\n",
    "    'inventory': 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-inventory.txt',\n",
    "    'countries': 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-countries.txt'\n",
    "}\n",
    "\n",
    "columns = {\n",
    "    'stations': ['station_id', 'latitude', 'longitude', 'elevation', 'description', 'flag', 'gsn', 'station_name'],\n",
    "    'inventory': ['station_id', 'latitude', 'longitude', 'measurement', 'start_year', 'end_year'],\n",
    "    \n",
    "}\n",
    "\n",
    "for name, url in url_dict:\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # read the content of the file into a pandas DataFrame\n",
    "        data = response.text\n",
    "        \n",
    "        # try reading the file as a fixed-width formatted file\n",
    "        df = pd.read_fwf(StringIO(data), header=None)\n",
    "\n",
    "        # assign the appropriate column names\n",
    "        df.columns = ['station_id', \n",
    "                    'latitude', \n",
    "                    'longitude', \n",
    "                    'elevation', \n",
    "                    'description',\n",
    "                    'flag', \n",
    "                    'gsn', \n",
    "                    'station_name']\n",
    "        \n",
    "        # convert to polars\n",
    "        stations = pl.from_pandas(df)\n",
    "        print(stations)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also read in the inventory and country code tables, found at the same location as the station list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "9 columns passed, passed data had 14 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 9 columns passed, passed data had 14 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend(cleaned_line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# convert the list of rows into a pandas DataFrame\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstation_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43melevation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mus_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgsn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstation_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 9 columns passed, passed data had 14 columns"
     ]
    }
   ],
   "source": [
    "# define the file path\n",
    "file_path = 'data/ghcnd-stations.txt'\n",
    "\n",
    "# initialize an empty list to store the processed rows\n",
    "rows = []\n",
    "\n",
    "# open the file and process each line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # clean up the line (normalize whitespaces)\n",
    "        cleaned_line = re.sub(r'\\s+', ' ', line.strip())\n",
    "        \n",
    "        # split the cleaned line into columns (space-separated)\n",
    "        rows.append(cleaned_line.split(' '))\n",
    "\n",
    "# convert the list of rows into a pandas DataFrame\n",
    "df = pd.DataFrame(rows, columns=['station_id', 'latitude', 'longitude', 'elevation', \n",
    "                                  'us_state', 'location_name', \n",
    "                                  'flag', 'gsn', 'station_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 8\n",
      "             0        1        2  ...    5    6        7\n",
      "0  ACW00011604  17.1167 -61.7833  ...  NaN  NaN      NaN\n",
      "1  ACW00011647  17.1333 -61.7833  ...  NaN  NaN      NaN\n",
      "2  AE000041196  25.3330  55.5170  ...  NaN  GSN  41196.0\n",
      "3  AEM00041194  25.2550  55.3640  ...  NaN  NaN  41194.0\n",
      "4  AEM00041217  24.4330  54.6510  ...  NaN  NaN  41217.0\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# fetch the file from the URL\n",
    "url = 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt'\n",
    "response = requests.get(url)\n",
    "\n",
    "# check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # read the content of the file into a pandas DataFrame\n",
    "    data = response.text\n",
    "    df = pd.read_fwf(StringIO(data), header=None)\n",
    "    \n",
    "    # Display the number of columns and the first few rows to understand its structure\n",
    "    print(f\"Number of columns: {df.shape[1]}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "expected at least 1 source",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m cleaned_data_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cleaned_data)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Read the cleaned data into a Polars DataFrame\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df_polars \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_data_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Assign column names\u001b[39;00m\n\u001b[1;32m     20\u001b[0m df_polars\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melevation\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     21\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/polars/_utils/deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/polars/_utils/deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/polars/_utils/deprecation.py:92\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     90\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/polars/io/csv/functions.py:534\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, skip_lines, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m prepare_file_arg(\n\u001b[1;32m    528\u001b[0m         source,\n\u001b[1;32m    529\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    533\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m--> 534\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43m_read_csv_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnull_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnull_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8-lossy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m            \u001b[49m\u001b[43meol_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mglob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_columns:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _update_columns(df, new_columns)\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/polars/io/csv/functions.py:670\u001b[0m, in \u001b[0;36m_read_csv_impl\u001b[0;34m(source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, skip_lines, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[1;32m    643\u001b[0m scan \u001b[38;5;241m=\u001b[39m scan_csv(\n\u001b[1;32m    644\u001b[0m     source,\n\u001b[1;32m    645\u001b[0m     has_header\u001b[38;5;241m=\u001b[39mhas_header,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    667\u001b[0m     glob\u001b[38;5;241m=\u001b[39mglob,\n\u001b[1;32m    668\u001b[0m )\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_str_sequence(columns, allow_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scan\u001b[38;5;241m.\u001b[39mselect(columns)\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/polars/lazyframe/frame.py:2057\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _check_order, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mComputeError\u001b[0m: expected at least 1 source"
     ]
    }
   ],
   "source": [
    "# Fetch file from the URL\n",
    "url = 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Normalize whitespace and handle the data\n",
    "    cleaned_data = [re.sub(r'\\s+', ' ', line.strip()) for line in response.text.splitlines()]\n",
    "\n",
    "    # Join the cleaned lines into a single string\n",
    "    cleaned_data_str = '\\n'.join(cleaned_data)\n",
    "\n",
    "    # Read the cleaned data into a Polars DataFrame\n",
    "    df_polars = pl.read_csv(cleaned_data_str, \n",
    "                            has_header=False,\n",
    "                            separator=' ',\n",
    "                            truncate_ragged_lines=True)\n",
    "\n",
    "    # Assign column names\n",
    "    df_polars.columns = ['station_id', 'latitude', 'longitude', 'elevation', \n",
    "                         'location_name', 'flag', 'gsn', 'station_name']\n",
    "\n",
    "    # Display the first few rows\n",
    "    print(df_polars.head())\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also read in the inventory and country code tables, found at the same location as the station list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch file from URL\n",
    "url = 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt'\n",
    "response = requests.get(url)\n",
    "\n",
    "# check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # read the content of the file into a pandas DataFrame\n",
    "    data = response.text\n",
    "    df = pd.read_fwf(StringIO(data), header=None)\n",
    "    \n",
    "    # assign column names\n",
    "    df.columns = ['station_id', \n",
    "                  'latitude', \n",
    "                  'longitude', \n",
    "                  'elevation', \n",
    "                  'location_name', \n",
    "                  'flag', \n",
    "                  'gsn', \n",
    "                  'station_name']\n",
    "    \n",
    "    # save to polars and \n",
    "    # display the first few rows\n",
    "    df = pl.from_pandas(df)\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-inventory.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>location_name</th>\n",
       "      <th>flag</th>\n",
       "      <th>station_name</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>10.1</td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>19.2</td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>34.0</td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GSN</td>\n",
       "      <td>41196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>10.4</td>\n",
       "      <td>DUBAI INTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>26.8</td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id  latitude  longitude  ...  flag station_name    other\n",
       "0  ACW00011604   17.1167   -61.7833  ...   NaN          NaN      NaN\n",
       "1  ACW00011647   17.1333   -61.7833  ...   NaN          NaN      NaN\n",
       "2  AE000041196   25.3330    55.5170  ...   NaN          GSN  41196.0\n",
       "3  AEM00041194   25.2550    55.3640  ...   NaN          NaN  41194.0\n",
       "4  AEM00041217   24.4330    54.6510  ...   NaN          NaN  41217.0\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['station_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No lookup list found for stations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               station  ...           retrieved\n",
      "0    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "1    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "2    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "3    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "4    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "..                 ...  ...                 ...\n",
      "361  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "362  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "363  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "364  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "365  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
      "\n",
      "[366 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define date range and parameters\n",
    "dataset_id = \"GHCND\"\n",
    "datatype_ids = [\"PRCP\"]  # Precipitation data type\n",
    "start_date = date(2024, 1, 1)\n",
    "end_date = date(2024, 12, 31)\n",
    "\n",
    "# Retrieve all stations in a location\n",
    "stations = ncei.get_stations(\n",
    "    datasetid=dataset_id,\n",
    "    datatypeid=datatype_ids,\n",
    "    locationid=\"FIPS:06\",  # Location code for California\n",
    "    startdate=start_date,\n",
    "    enddate=end_date,\n",
    ")\n",
    "\n",
    "# Select a station with good data coverage\n",
    "station = sorted(stations.values(), key=lambda s: -int(s[\"datacoverage\"]))[0]\n",
    "\n",
    "# Retrieve precipitation data for the selected station\n",
    "response = ncei.get_data(\n",
    "    datasetid=dataset_id,\n",
    "    stationid=station[\"id\"],\n",
    "    datatypeid=datatype_ids,\n",
    "    startdate=start_date,\n",
    "    enddate=end_date,\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = response.to_dataframe()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>datatype</th>\n",
       "      <th>attributes</th>\n",
       "      <th>value</th>\n",
       "      <th>url</th>\n",
       "      <th>retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>12.7</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>T,,N,0700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>9.1</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0.3</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>1.3</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>10.9</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>GHCND:US1CACC0001</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.ncdc.noaa.gov/cdo-web/api/v2/data?...</td>\n",
       "      <td>2025-01-09 22:34:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               station  ...           retrieved\n",
       "0    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "1    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "2    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "3    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "4    GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "..                 ...  ...                 ...\n",
       "361  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "362  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "363  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "364  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "365  GHCND:US1CACC0001  ... 2025-01-09 22:34:14\n",
       "\n",
       "[366 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "GHCND:US1CACC0001    366\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['station'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datacoverage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_types \u001b[38;5;241m=\u001b[39m ncei\u001b[38;5;241m.\u001b[39mget_data_types()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pyncei/bot.py:1068\u001b[0m, in \u001b[0;36mNCEIResponse.to_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Writes data to a dataframe\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;124;03m        pandas.DataFrame or geopandas.GeoDataFrame if geopandas is installed\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;124;03m        and the responses include coordinates\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1068\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;66;03m# Convert datetime columns to datetime objects\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, date_format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate_formats\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pandas/core/frame.py:843\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    841\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dataclass(data[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pyncei/bot.py:1010\u001b[0m, in \u001b[0;36mNCEIResponse.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_order):\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1007\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unordered keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeys\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_order)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1008\u001b[0m         )\n\u001b[0;32m-> 1010\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[0;32m~/files/projects/dagster_ncei/.venv/lib/python3.11/site-packages/pyncei/bot.py:1010\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_order):\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1007\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unordered keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeys\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_order)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1008\u001b[0m         )\n\u001b[0;32m-> 1010\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m {k: \u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_order \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datacoverage'"
     ]
    }
   ],
   "source": [
    "data_types = ncei.get_data_types()\n",
    "print(data_types.to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
